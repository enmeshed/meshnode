import { Provider, Container } from '@enmeshed/alpha'
import lodash from "lodash"

// Preload Redis IOC resources
import '../redis/AnyClientPort'

Queue = require('bull')

export class Job:
  // Underlying Bull job object
  _nativeJob = null

  // Job json data
  data = {}

  // Number of concurrent instances that can run per worker node
  static concurrency = 1

  // Job options for Bull
  static jobOptions = {}

  static getQueueName(): string ->
    this.queueName

  static fromNativeJob(nativeJob) ->
    job = new this()
    job.setNativeJob(nativeJob)
    job.setData(nativeJob.data)
    job

  getQueueName(): string ->
    this.constructor.getQueueName()

  getData() -> this.data

  getOptions() ->
    this.constructor.jobOptions

  setData(data): void ->
    this.data = data

  setNativeJob(nj): void ->
    this._nativeJob = nj

export class Jobs extends Provider:
  static providerName = "jobs"
  static dependencies = {
    "redis": "redis"
    "events": "events"
  }

  static options = {
    // Reuse redis connections across queues?
    reuseConnections: true
    // Base Queue creation options
    baseQueueOpts: {}
  }

  defaultJobOpts = {
    attempts: 1
    removeOnComplete: 500
  }

  queues = {}

  init(): void -/> {
    log.info("initializing job subsystem")
    Container.retain(this)
    { redis } = this

    // Build base context for job subsystem
    this.baseContext = Context.create({
      base: Context.global()
      type: 'jobs'
    })
    this.baseContext.tracing.setTracer({tracer: 'job'})

    // Build redis queue options
    jobsOpts = this.constructor.options
    queueOpts = lodash.cloneDeep(jobsOpts.baseQueueOpts)
    if jobsOpts.reuseConnections:
      log.info("jobs: creating reusable redis connections")
      [cliConn, subConn, bcliConn] <- [redis.connection(), redis.connection(), redis.connection()]
      this.storedConnections = [cliConn, subConn, bcliConn]
      queueOpts.createClient = (type) ->
        match type:
          | 'client': cliConn
          | 'subscriber': subConn
          | 'bclient': bcliConn
          | else: throw new Error("invalid redis client type")
    else:
      queueOpts.redis = redis.getRedisOptions()
    this.queueOpts = queueOpts
  } // init()


  getQueue(name) ->
    if this.queues[name]:
      this.queues[name]
    else:
      log.info(`Creating new interface to job queue: ${name}`)
      queue = new Queue(name, this.queueOpts)
      queue.on('stalled', this.onJobStalled.bind(this, queue))
      this.queues[name] = queue

  onJobStalled(queue, job): void ->
    log.warn({ jobQueue: queue.name, jobId: job.id, data: job.data }, "Job stalled")
    this.events.fire("system.job.stalled", { jobQueue: queue.name, jobId: job.id, data: job.data })

  enqueueRaw(queueName, data, opts) ->
    queue = this.getQueue(queueName)
    log.info(`Enqueueing job to job queue: ${queueName}`)

    // Inject active context
    nextData = Object.assign({}, data)
    context = Context.current()
    nextData._context = context.toJSON()

    nextOpts = Object.assign({}, this.defaultJobOpts, opts)
    queue.add(nextData, nextOpts)

  processRaw(queueName, concurrency, handler, JobClass) ->
    log.trace(`processing jobs from queue ${queueName}`)
    queue = this.getQueue(queueName)
    queue.process(concurrency, this.wrapHandler(handler, queueName, JobClass))

  wrapHandler(handler, queueName, JobClass = Job) ->
    { baseContext, events } = this
    destinationName = `${queueName}`
    wrappedHandler(job) -/>
      { data } = job

      // Establish async context for job
      context = Context.push({
        type: 'event'
        base: baseContext
        parent: {
          relationship: 'followsFrom'
          json: data?._context
        }
      })
      context.tracing.startSpan({
        name: destinationName
        reference: {
          relationship: 'followsFrom'
          context: context.parent
        }
      })
      log.tag('span.kind', 'consumer')
      log.tag('message_bus.kind', 'job')
      log.tag('message_bus.destination', destinationName)
      log.trace({event: "processing_began"}, "processing job with data", { data })
      logHere = log.useContext(context)
      // Call wrapped handler
      try:
        // Instantiate wrapped job class
        wrappedJob = JobClass.fromNativeJob(job)
        events.fire("system.job.started", { jobQueue: queueName, data })
        <- handler(wrappedJob)
        events.fire("system.job.completed", { jobQueue: queueName, data })
      catch err:
        logHere.error({err})
        // Discard jobs that encounter non-transient errors
        if not err.retry:
          logHere.info('discarding job for non-retriable error')
          job.discard().catch((err) -> logHere.error({err}, "error while discarding job"))
      finally:
        logHere.trace({event: 'processing_finished'})
        context.tracing?.finishSpan()

  enqueue(job: Job) -/>
    nj <- this.enqueueRaw(job.getQueueName(), job.getData(), job.getOptions())
    job.setNativeJob(nj)
    job

  process(JobClass, handler) ->
    this.processRaw(JobClass.getQueueName(), JobClass.concurrency, handler, JobClass)

  processAll(bindings): void ->
    for elem [jobClass, handler] in bindings:
      this.process(jobClass, handler)

  destroy(): void -/>
    { redis } = this
    if this.queues:
      log.info(`jobs: closing queues`)
      <- [...for val queue in this.queues: [queue.close()]]
    if this.storedConnections:
      log.info(`jobs: closing redis conns`)
      <- [...for elem conn in this.storedConnections: [redis.disconnect(conn)]]

Container.provide(Jobs)
